{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d8c571",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Hey-friends-:)\" data-toc-modified-id=\"Hey-friends-:)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Hey friends :)</a></span></li><li><span><a href=\"#Compartment-Architecture\" data-toc-modified-id=\"Compartment-Architecture-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Compartment Architecture</a></span></li><li><span><a href=\"#Data-Pre-processing\" data-toc-modified-id=\"Data-Pre-processing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Pre-processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#outflows_data\" data-toc-modified-id=\"outflows_data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>outflows_data</a></span></li><li><span><a href=\"#transitions_data\" data-toc-modified-id=\"transitions_data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>transitions_data</a></span></li><li><span><a href=\"#total_population_data\" data-toc-modified-id=\"total_population_data-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>total_population_data</a></span></li><li><span><a href=\"#Uploading-our-data\" data-toc-modified-id=\"Uploading-our-data-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Uploading our data</a></span></li></ul></li><li><span><a href=\"#Running-a-baseline\" data-toc-modified-id=\"Running-a-baseline-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Running a baseline</a></span></li><li><span><a href=\"#Running-a-policy-scenario\" data-toc-modified-id=\"Running-a-policy-scenario-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Running a policy scenario</a></span></li><li><span><a href=\"#Extensions\" data-toc-modified-id=\"Extensions-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Extensions</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#We-collapsed-jail-and-prison-into-a-single-compartment,-but-they-likely-behave-very-differently-in-real-life.-Go-back-to-the-beginning-and-re-do-the-processing-after-adding-a-jail-compartment-to-the-model-architecture.\" data-toc-modified-id=\"We-collapsed-jail-and-prison-into-a-single-compartment,-but-they-likely-behave-very-differently-in-real-life.-Go-back-to-the-beginning-and-re-do-the-processing-after-adding-a-jail-compartment-to-the-model-architecture.-6.0.1\"><span class=\"toc-item-num\">6.0.1&nbsp;&nbsp;</span>We collapsed jail and prison into a single compartment, but they likely behave very differently in real life. Go back to the beginning and re-do the processing after adding a jail compartment to the model architecture.</a></span></li><li><span><a href=\"#Can-you-implement-a-different-policy-(or-the-same-one)-using-a-different-policy-function-from-CompartmentTransitions.apply_reduction()?\" data-toc-modified-id=\"Can-you-implement-a-different-policy-(or-the-same-one)-using-a-different-policy-function-from-CompartmentTransitions.apply_reduction()?-6.0.2\"><span class=\"toc-item-num\">6.0.2&nbsp;&nbsp;</span>Can you implement a different policy (or the same one) using a different policy function from CompartmentTransitions.apply_reduction()?</a></span></li><li><span><a href=\"#Can-you-add-recidivism-into-the-model?\" data-toc-modified-id=\"Can-you-add-recidivism-into-the-model?-6.0.3\"><span class=\"toc-item-num\">6.0.3&nbsp;&nbsp;</span>Can you add recidivism into the model?</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b4c2f",
   "metadata": {},
   "source": [
    "# Hey friends :)\n",
    "This notebook will walk you thru running your first policy simulation (woooooo!). You should run each cell of code– starting with the imports under this text–working down the notebook sequentially. There will be text boxes like this one instructing you what you need to fill in to get stuff working. \n",
    "\n",
    "You're encouraged to experiment, visualize, and add cells as you please. You don't need to understand every line of code you're running, but obviously you can look up functions and stuff that did nifty things you want to be able to reproduce. DM Tori or Paco on Slack if you get stuck <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b519419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.relpath('../../')) \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from super_simulation.super_simulation_factory import SuperSimulationFactory\n",
    "from transition_table import TransitionTable\n",
    "from spark_policy import SparkPolicy\n",
    "from utils.spark_bq_utils import upload_spark_model_inputs\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99227b4",
   "metadata": {},
   "source": [
    "# Compartment Architecture\n",
    "The first step in Spark modeling is always to decide what compartment architecture you want to build around. In our case, we're gonna use this one:\n",
    "\n",
    "**'pretrial' (shell compartment) --> 'prison' (full compartment) --> 'release' (full compartment)**\n",
    "\n",
    "Make sure you use these three compartment names in your data processing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d7b43",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "We're skipping the early part for now, but you'll still need to get from \"clean\" data to the data inputs that the Spark model ingests. Feel free to run this cell without thinking about it too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb94245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_va_sentence_df = pd.read_csv(\n",
    "    '../../state/VA/VA_data/unprocessed_va_historical_sentences_v2.csv',\n",
    "    sep='\\t'\n",
    ")\n",
    "raw_va_sentence_df['crime_type'] = raw_va_sentence_df['Offense Group'].ffill()\n",
    "raw_va_sentence_df['offense_code'] = raw_va_sentence_df['VCC'].ffill()\n",
    "raw_va_sentence_df['crime'] = raw_va_sentence_df['Off1VCC'].ffill()\n",
    "raw_va_sentence_df['judge_id'] = raw_va_sentence_df['JudgeID'].ffill()\n",
    "raw_va_sentence_df['sentence_type_code'] = raw_va_sentence_df['ActDisp'].ffill()\n",
    "raw_va_sentence_df['effective_sentence_months'] = raw_va_sentence_df['effsent']\n",
    "raw_va_sentence_df['fiscal_year'] = raw_va_sentence_df['FiscalYr'].ffill()\n",
    "raw_va_sentence_df['life_sentence'] = raw_va_sentence_df['EffLif']\n",
    "raw_va_sentence_df = raw_va_sentence_df.rename({'Off1Date':'offense_date'}, axis=1)\n",
    "raw_va_sentence_df = raw_va_sentence_df[raw_va_sentence_df.sentence_type_code != 1]\n",
    "raw_va_sentence_df = raw_va_sentence_df[raw_va_sentence_df.effective_sentence_months != 0]\n",
    "\n",
    "\n",
    "raw_va_sentence_df = raw_va_sentence_df[~raw_va_sentence_df['crime_type'].str.contains('Total')]\n",
    "raw_va_sentence_df = raw_va_sentence_df.drop(\n",
    "    ['VCC', 'Offense Group', 'Off1VCC', 'JudgeID', 'ActDisp', 'effsent', 'FiscalYr', 'EffLif'],\n",
    "    axis=1\n",
    ")\n",
    "raw_va_sentence_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22536ebc",
   "metadata": {},
   "source": [
    "We can see the first few rows of the dataset above, but let's take a slightly more comprehensive peak at what's in here before we move on! You can run the following cells without changing anything, but feel free to play with them anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always a good place to start!\n",
    "raw_va_sentence_df.describe([0.05,0.25,0.5,0.75,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aae00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine first and last name into one full name and check the number of rows of data per person\n",
    "raw_va_sentence_df['full_name'] = raw_va_sentence_df.OffFName + ' ' + raw_va_sentence_df.OffLName\n",
    "sentences_per_person = raw_va_sentence_df.groupby('full_name').count().sort_values('OffLName', ascending=False)\n",
    "plt.hist(sentences_per_person.OffLName, bins = 30)\n",
    "plt.ylabel('number of people')\n",
    "plt.xlabel('number of rows of data per person')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fce95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap sentence lengths at 25 years, then plot the sentence length distribution in months.\n",
    "temp = raw_va_sentence_df.copy()\n",
    "temp.loc[temp.effective_sentence_months > 12 * 25, 'effective_sentence_months'] = 12 * 25\n",
    "plt.hist(temp.effective_sentence_months, bins=40)\n",
    "plt.ylabel('number of people')\n",
    "plt.xlabel('length of sentence in months')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef54a5",
   "metadata": {},
   "source": [
    "## outflows_data\n",
    "Ok, time to process our data! First up is the outflows_data table. As a reminder, outflows_data counts the number of people transitioning historically into and throughout the system. It should have one row of data per sub-group per time-step per compartment (although in our case we'll only bother with outflows for the pretrial compartment). Here is what a final outflows_data table should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'compartment': ['pretrial'] * 4,\n",
    "    'outflow_to': ['probation'] * 4,\n",
    "    'crime_type': ['VIOLENT'] * 2 + ['NONVIOLENT'] * 2,\n",
    "    'time_step': [0,1, 0, 1],\n",
    "    'total_population': [250, 233, 850, 912]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b88e31",
   "metadata": {},
   "source": [
    "Okie you're up! Turn `raw_va_sentence_df` into an outflows_data table! Some important tips for this:\n",
    "* Make sure you make a copy of `raw_va_sentence_df` and mess with that. If you start changing the original you won't have anything to build the other data inputs with.\n",
    "* Make sure your table has exactly the right columns with the right names when you're done. df.rename() is your friend!\n",
    "* `time_step` is the number of steps away from the reference date you're at. So with a reference date of 2020.0, 2021.0 would be time_step = 12. In our case, the reference_date is 2019.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaec467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Use a groupby operation to get one row per crime_type per year.\n",
    "\n",
    "#* your code here *\n",
    "\n",
    "# Step 2: Change the data to be per month instead of per year. Your table should get 12 times longer when you do this.\n",
    "\n",
    "#* your code here *\n",
    "    \n",
    "# Step 3: Add in any of the columns you're missing, drop any you don't want, and rename the ones you want to keep.\n",
    "# Your column names should now match the example exactly.\n",
    "\n",
    "#* your code here *\n",
    "\n",
    "# Step 4: Ensure the columns of our table have the correct types. In particular, make sure the `time_step` column\n",
    "# has type int and `total_population` column has type float.\n",
    "\n",
    "#* your code here *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4562a9",
   "metadata": {},
   "source": [
    "Woooo look at you go!! Now let's take a look at what we just made and sanity-check that it looks reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflows_data.groupby(['time_step', 'crime_type']).total_population.mean().unstack('crime_type').plot()\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b5386d",
   "metadata": {},
   "source": [
    "Huh, that's kinda hard to parse. Let's try pulling out just one crime type to look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to try subbing in a few different crimes to look at them one at a time\n",
    "CRIME_TYPE = 'ASSAULT'\n",
    "outflows_data.groupby(['time_step', 'crime_type']).total_population.mean().unstack('crime_type')[[CRIME_TYPE]].plot(ylim=[0,150])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d14f5f",
   "metadata": {},
   "source": [
    "## transitions_data\n",
    "On to the transitions_data table. As a reminder, transitions_data should have one row of data per sub-group per compartment duration (aka length of stay) per full compartment (aka every one except pretrial). Here is what a final transitions table should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'compartment': ['prison'] * 3 + ['release'] * 2,\n",
    "    'outflow_to': ['release'] * 5,\n",
    "    'crime_type': ['VIOLENT', 'VIOLENT', 'NONVIOLENT', 'VIOLENT', 'NONVIOLENT'],\n",
    "    'compartment_duration': [48,156, 30, 1, 1],\n",
    "    'total_population': [0.6, 0.4, 1, 1, 1]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186eca0",
   "metadata": {},
   "source": [
    "Okie you're up! Turn `raw_va_sentence_df` into a transitions_data table! Some important tips for this:\n",
    "* Make sure you make a copy of `raw_va_sentence_df` and mess with that. If you start changing the original you won't have anything to build the other data inputs with.\n",
    "* Make sure your table has exactly the right columns with the right names when you're done. df.rename() is your friend!\n",
    "* The total_population column of this table only cares about the ratio of values between compartment_duration values within a given subgroup and compartment. In other words, compartment_duration : total_population = (12 : 0.2, 24: 0.4, 36: 0.4) will give the same behavior as compartment_duration : total_population = (12: 20, 24: 40, 36: 40).\n",
    "* Our time steps are one month, make sure the units of your `compartment_duration` column are correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Use a groupby operation to get one row per crime_type per sentence length.\n",
    "\n",
    "#* your code here *\n",
    "\n",
    "# Step 2: Add in any of the columns you're missing, drop any you don't want, and rename the ones you want to keep.\n",
    "# Your column names should now match the example exactly.\n",
    "\n",
    "#* your code here *\n",
    "\n",
    "# Step 3: You've now finished the transitions data for the prison compartment, but we still need transitions data\n",
    "# for the release compartment. For our purposes, we're gonna assume no recidivism, which means people can just go\n",
    "# from release back to release (just like the example above). Create a second transitions_data table for release\n",
    "# that has one trivial transition from release to itself for each subgroup.\n",
    "\n",
    "#* your code here *\n",
    "\n",
    "# Step 4: Concatenate your two transitions tables together to get one final transitions_data\n",
    "\n",
    "#* your code here *\n",
    "\n",
    "# Step 5: Ensure the columns of our table have the correct types. In particular, make sure the `compartment_duration`\n",
    "# and `total_population` columns both have type float.\n",
    "\n",
    "#* your code here *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6badaf",
   "metadata": {},
   "source": [
    "Killin it!! Now let's take a look at what we just made and sanity-check that it looks reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbcbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only looking at the prison compartment transitions for this check.\n",
    "transitions_data[transitions_data.compartment == 'prison'].groupby(\n",
    "    ['compartment_duration', 'crime_type']\n",
    ").total_population.mean().unstack('crime_type').plot()\n",
    "plt.legend(bbox_to_anchor=(1.8, 1.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e331689",
   "metadata": {},
   "source": [
    "Huh, that's also kinda hard to parse. Let's try pulling out just one crime type to look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb42bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to try subbing in a few different crimes to look at them one at a time\n",
    "CRIME_TYPE = 'ASSAULT'\n",
    "transitions_data[transitions_data.compartment == 'prison'].groupby(\n",
    "    ['compartment_duration', 'crime_type']\n",
    ").total_population.mean().unstack('crime_type')[[CRIME_TYPE]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5135f8",
   "metadata": {},
   "source": [
    "## total_population_data\n",
    "Last but not least: the total_population table. You'll have to go grab data for this one yourself, the data you need is on page 37 of this [report](https://vadoc.virginia.gov/media/1623/vadoc-financial-annual-mis-report-2020.pdf). `total_population_data` is the only table that doesn't need to be disaggreagted by subgroup if the data isn't there for that, so we'll just be creating a table for the total prison population and no disaggregation axis.\n",
    "\n",
    "As a reminder, total_population_data should have one row of data per time step per full compartment (in our case just `prison`). Here is what a final populations table should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'compartment': ['prison'] * 4,\n",
    "    'time_step': range(3,7),\n",
    "    'total_population': [2500, 2800, 3030, 2820]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2c6dc",
   "metadata": {},
   "source": [
    "Okie you're up! Turn the table from the DOC report into a `total_population_data` table! Some important tips for this:\n",
    "* Make sure your table has exactly the right columns with the right names when you're done. df.rename() is your friend!\n",
    "* `time_step` is the number of steps away from the reference date you're at. So with a reference date of 2020.0, 2021.0 would be time_step = 12. In our case, the reference_date is 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecca530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the data from the DOC report into a pandas DataFrame. Feel free to start with the example table\n",
    "# above if that's easier. \n",
    "\n",
    "#* your code here *\n",
    "\n",
    "# Time steps are based on 2019.0=Jan 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e677f",
   "metadata": {},
   "source": [
    "Let's double check that matches the report we copied from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da5b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_population_data.plot(x='time_step', y='total_population')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a3ec0d",
   "metadata": {},
   "source": [
    "## Uploading our data\n",
    "The final step in pre-processing is to upload our data to Google BigQuery. If this next cell gives you a permission error, you need to go set up your Google Cloud access–follow these steps:\n",
    "1. Work through just the installation section of (this page)[https://cloud.google.com/sdk/docs/quickstart]. Make sure you log in with your Stanford email.\n",
    "2. Open a terminal window and navigate to your Github repository folder. Run the following commands:\n",
    "3. `gcloud auth application-default login` --> This will prompt you to log in to your google cloud account\n",
    "4. `gcloud config set project recidiviz-staging`\n",
    "\n",
    "Once you're set up, you can try the upload again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd921c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: pick a `simulation_tag` for your simulation. \"paco_parole_test\" would be a reasonable example...\n",
    "simulation_tag = \"parole_tutorial\"\n",
    "\n",
    "\n",
    "upload_spark_model_inputs(\n",
    "    \"recidiviz-staging\",\n",
    "    simulation_tag,\n",
    "    outflows_data,\n",
    "    transitions_data,\n",
    "    total_population_data,\n",
    "    '../../state/VA/2022/test_configurations/walkthru_user_inputs.yaml',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5d0d2",
   "metadata": {},
   "source": [
    "# Running a baseline\n",
    "We're ready to build a simulation now! First step is initializing a simulation object, called a SuperSimulation. When we initialize it we pass in the filepath of our YAML configuration, so before you continue you need to go to that file, located in `recidiviz-data/recidiviz/calculator/modeling/population_projection/state/VA/2022/test_configurations`, and change the simulation_tag to match the one you chose above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about any warnings, as long as this doesn't fail you're in business\n",
    "spark_sim = SuperSimulationFactory.build_super_simulation(\n",
    "    '../../state/VA/2022/test_configurations/walkthru_user_inputs.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c19517e",
   "metadata": {},
   "source": [
    "Now we're going to run a baseline simulation. This is an oppportunity to make sure the data we generated is valid, and to sanity-check the basic dynamics it generates. You should just be able to run the code below, but if you feel like it you can also include `release` in the `display_compartments` list to see that population evolve too.\n",
    "*Make sure you pause to think about the graph this generates*. Do you believe this is actually close to reality? Is there something off, and if so what might be causing it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This can take several minutes to run. You'll see six checkpoints printed out along the way before it finishes.\n",
    "display_compartments = ['prison']\n",
    "spark_sim.simulate_baseline(display_compartments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84349840",
   "metadata": {},
   "source": [
    "Before we move on, the other thing we can check is the timesacle analysis (ARIMA) fits that the `pretrial` compartment generated based on our outflows data. Two things to look for:\n",
    "* Does this trend(s) look believable? Do we think we're capturing a reasonable guess for what could happen going forward?\n",
    "* Notice any places where a fit is steep up or down and then appruptly flattens. That's a place where the model has enforced that outflows cannot deviate from the present by more than 50%. This is an arbitrary insertion, so it's usually bad news bears if we actually hit that limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706dd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With `by_simulation_group` set to false, you'll only see one aggregate graph. If you want to see the ARIMA fits\n",
    "# for each of the subgroups separately, set that to true and run again.\n",
    "spark_sim.get_arima_output_plots('baseline_middle', by_simulation_group=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bbfca6",
   "metadata": {},
   "source": [
    "# Running a policy scenario\n",
    "I've filled out a lot of the code for you here, but once you finish out the missing pieces definitely play around with the stuff I did for you. The whole appeal of the Spark model is how easy it is to test out different policy scenarios once you get the baseline running.\n",
    "\n",
    "Without worrying about all the details, the main thing to understand here is that a policy function transforms the transitions data of a given compartment. By applying one or multiple per compartment that is affected in the policy scneario, we can simulate the effects of the reform in question. `policy_list` is thus just a list of policy functions that gets passed into the simulation so it knows what to change in the policy scenario.\n",
    "\n",
    "Some important pointers:\n",
    "* A SparkPolicy specifies both compartment and subgroup. If you want a policy to apply to every subgroup you need one SparkPolicy per subgroup!\n",
    "* Retroactivity determines whether or not a policy applies to people who are already incarcerated. Try toggling it on and off and see what happens!\n",
    "* Order matters! If policy A shortens sentences by 50% and policy B shortens them by 1 year, the policy_list [A,B] will be different frmo the policy_list [B,A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e73ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start, let's model enabling parole by shortening the fraction of their sentence that people must serve.\n",
    "# Currently, they cannot serve less than 85%. Let's suppose that this policy will bring that number down to 60%.\n",
    "# Think about how you should shorten prison transitions to capture that change, then pick the appropriate parameters\n",
    "# below!\n",
    "LOS_REDUCTION = ?? # This parameter determines how much shorter compartment duration gets for affected individuals.\n",
    "AFFECTED_FRACTION = ?? # This parameter determins the fraction of the compartment population affected by the change.\n",
    "REDUCTION_TYPE = ?? #T his should either be '*' or '+'. If you make it '+', it will change compartment_duration L to\n",
    "                    # L - LOS_REDUCTION. If you make it '*', it will change L to L * (1 - LOS_REDUCTION)\n",
    "RETROACTIVE = ?? # This should either be True or False\n",
    "\n",
    "#### Should not have to change things below this line for this cell ####\n",
    "\n",
    "def apply_reinstated_parole():\n",
    "    return partial(TransitionTable.apply_reduction, \n",
    "                   reduction_df=pd.DataFrame({\n",
    "                       'outflow': [OUTFLOW],\n",
    "                       'reduction_size': [LOS_REDUCTION], \n",
    "                       'affected_fraction': [AFFECTED_FRACTION]\n",
    "                   }),\n",
    "                   reduction_type=REDUCTION_TYPE,\n",
    "                   retroactive=RETROACTIVE)\n",
    "\n",
    "# Note that I've created for you in this example, and picked it to apply the policy to all subgroups.\n",
    "policy_list = [SparkPolicy(policy_fn=apply_reinstated_parole(),\n",
    "                                           spark_compartment='prison',\n",
    "                                           sub_population={'crime_type': crime},\n",
    "                                           policy_ts=24,\n",
    "                                           apply_retroactive=RETROACTIVE) \n",
    "                               for crime in transitions_data.crime_type.unique()]\n",
    "    \n",
    "test_results = spark_sim.simulate_policy(policy_list, 'prison')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a907e",
   "metadata": {},
   "source": [
    "How do those results look? Does this match your expectation for the magnitude of this policy's impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d44516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try mixing it up a bit. Now I want you to try changing the policy so it only applies to \n",
    "# non-violent offenders. What crime_types will that be? How should you change your code to account for this?\n",
    "# Hint: the only thing inside the parentheses that create the SparkPolicy object that you should need to change is\n",
    "# the `sub_population`.\n",
    "\n",
    "LOS_REDUCTION = ??\n",
    "AFFECTED_FRACTION = ??\n",
    "REDUCTION_TYPE = ??\n",
    "RETROACTIVE = ??\n",
    "\n",
    "def apply_reinstated_parole():\n",
    "    return partial(TransitionTable.apply_reduction, \n",
    "                   reduction_df=pd.DataFrame({\n",
    "                       'outflow': [OUTFLOW],\n",
    "                       'reduction_size': [LOS_REDUCTION], \n",
    "                       'affected_fraction': [AFFECTED_FRACTION]\n",
    "                   }),\n",
    "                   reduction_type=REDUCTION_TYPE,\n",
    "                   retroactive=RETROACTIVE)\n",
    "\n",
    "policy_list = [SparkPolicy(policy_fn=apply_reinstated_parole(),\n",
    "                                           spark_compartment='prison',\n",
    "                                           sub_population={'crime_type': crime},\n",
    "                                           policy_ts=24,\n",
    "                                           apply_retroactive=RETROACTIVE) \n",
    "                               for crime in transitions_data.crime_type.unique()]\n",
    "    \n",
    "test_results = spark_sim.simulate_policy(policy_list, 'prison')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f3abd",
   "metadata": {},
   "source": [
    "How do these results compare to your previous scenario? Is it more or less? By how much? Can you think of a way to validate that that result is reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c152a",
   "metadata": {},
   "source": [
    "# Extensions\n",
    "WOOOOOO GOOOO YOUUUUUUUU!!!! That's right, you finished the notebook :)\n",
    "That said, there's tons more to learn, so if you enjoyed that and want to try some more complex variations, here are some extensions:\n",
    "\n",
    "### We collapsed jail and prison into a single compartment, but they likely behave very differently in real life. Go back to the beginning and re-do the processing after adding a jail compartment to the model architecture. \n",
    "A few hints:\n",
    "1. sentence_type_code == 3 means prison, == 2 equals jail.\n",
    "2. You'll need to go into the YAML configuration and add a row for jail under every row for prison\n",
    "3. Bonus: how should we change the policy_list to account for this change?\n",
    "\n",
    "### Can you implement a different policy (or the same one) using a different policy function from CompartmentTransitions.apply_reduction()?\n",
    "A few hints:\n",
    "1. You'll want to go into the 'transitions_table' file in the codebase and scroll to the bottom, where the policy functions are defined, to see what you can try.\n",
    "2. The mechanics are all the same otherwise, so the only thing you should have to change in is the `apply_reinstated_parole` function.\n",
    "\n",
    "### Can you add recidivism into the model?\n",
    "A few hints:\n",
    "1. The relevant place to make this change is in the transitions_data pre-processing, where we simply assumed everyone in `release` stays there forever. You'll want to add a probability of going back to prison.\n",
    "2. You'll have to do a little digging on the DOC's website to find statistics for recidivism"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
