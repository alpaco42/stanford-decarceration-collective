{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d8c571",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Hey-friends-:)\" data-toc-modified-id=\"Hey-friends-:)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Hey friends :)</a></span></li><li><span><a href=\"#Compartment-Architecture\" data-toc-modified-id=\"Compartment-Architecture-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Compartment Architecture</a></span></li><li><span><a href=\"#Data-Pre-processing\" data-toc-modified-id=\"Data-Pre-processing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Pre-processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#outflows_data\" data-toc-modified-id=\"outflows_data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>outflows_data</a></span></li><li><span><a href=\"#transitions_data\" data-toc-modified-id=\"transitions_data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>transitions_data</a></span></li><li><span><a href=\"#total_population_data\" data-toc-modified-id=\"total_population_data-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>total_population_data</a></span></li><li><span><a href=\"#Uploading-our-data\" data-toc-modified-id=\"Uploading-our-data-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Uploading our data</a></span></li></ul></li><li><span><a href=\"#Running-a-baseline\" data-toc-modified-id=\"Running-a-baseline-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Running a baseline</a></span></li><li><span><a href=\"#Running-a-policy-scenario\" data-toc-modified-id=\"Running-a-policy-scenario-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Running a policy scenario</a></span></li><li><span><a href=\"#Extensions\" data-toc-modified-id=\"Extensions-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Extensions</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Outflows-data\" data-toc-modified-id=\"Outflows-data-6.0.1\"><span class=\"toc-item-num\">6.0.1&nbsp;&nbsp;</span>Outflows data</a></span></li><li><span><a href=\"#Transitions-data\" data-toc-modified-id=\"Transitions-data-6.0.2\"><span class=\"toc-item-num\">6.0.2&nbsp;&nbsp;</span>Transitions data</a></span></li><li><span><a href=\"#Total-population-data\" data-toc-modified-id=\"Total-population-data-6.0.3\"><span class=\"toc-item-num\">6.0.3&nbsp;&nbsp;</span>Total population data</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b4c2f",
   "metadata": {},
   "source": [
    "# Hey friends :)\n",
    "This notebook will walk you thru running your first policy simulation (woooooo!). You should run each cell of code– starting with the imports under this text–working down the notebook sequentially. There will be text boxes like this one instructing you what you need to fill in to get stuff working. \n",
    "\n",
    "You're encouraged to experiment, visualize, and add cells as you please. You don't need to understand every line of code you're running, but obviously you can look up functions and stuff that did nifty things you want to be able to reproduce. DM Tori or Paco on Slack if you get stuck <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b519419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.relpath('../../')) \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from super_simulation.super_simulation_factory import SuperSimulationFactory\n",
    "from transition_table import TransitionTable\n",
    "from spark_policy import SparkPolicy\n",
    "from utils.spark_bq_utils import upload_spark_model_inputs\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99227b4",
   "metadata": {},
   "source": [
    "# Compartment Architecture\n",
    "The first step in Spark modeling is always to decide what compartment architecture you want to build around. In our case, we're gonna use this one:\n",
    "\n",
    "**'pretrial' (shell compartment) --> 'prison' (full compartment) --> 'release' (full compartment)**\n",
    "\n",
    "Make sure you use these three compartment names in your data processing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d7b43",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "We're skipping the early part for now, but you'll still need to get from \"clean\" data to the data inputs that the Spark model ingests. Feel free to run this cell without thinking about it too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb94245e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offense_date</th>\n",
       "      <th>OffLName</th>\n",
       "      <th>OffFName</th>\n",
       "      <th>crime_type</th>\n",
       "      <th>offense_code</th>\n",
       "      <th>crime</th>\n",
       "      <th>judge_id</th>\n",
       "      <th>sentence_type_code</th>\n",
       "      <th>effective_sentence_months</th>\n",
       "      <th>fiscal_year</th>\n",
       "      <th>life_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/20/2017</td>\n",
       "      <td>MOORE</td>\n",
       "      <td>KENNETH</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>ASL1316</td>\n",
       "      <td>ASL1316F6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/25/2018</td>\n",
       "      <td>CLINE</td>\n",
       "      <td>MATTHEW</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>ASL1316</td>\n",
       "      <td>ASL1316F6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/25/2016</td>\n",
       "      <td>MILLER</td>\n",
       "      <td>MARCUS</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>ASL1316</td>\n",
       "      <td>ASL1316F6</td>\n",
       "      <td>10DB</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11/17/2018</td>\n",
       "      <td>SPRADLEY</td>\n",
       "      <td>CALEB</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>ASL1316</td>\n",
       "      <td>ASL1316F6</td>\n",
       "      <td>10DB</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12/11/2016</td>\n",
       "      <td>JAMES</td>\n",
       "      <td>ERIC</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>ASL1316</td>\n",
       "      <td>ASL1316F6</td>\n",
       "      <td>10KW</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  offense_date  OffLName OffFName crime_type offense_code      crime judge_id  \\\n",
       "0    5/20/2017     MOORE  KENNETH    ASSAULT      ASL1316  ASL1316F6        0   \n",
       "1    4/25/2018     CLINE  MATTHEW    ASSAULT      ASL1316  ASL1316F6        0   \n",
       "4   12/25/2016    MILLER   MARCUS    ASSAULT      ASL1316  ASL1316F6     10DB   \n",
       "5   11/17/2018  SPRADLEY    CALEB    ASSAULT      ASL1316  ASL1316F6     10DB   \n",
       "7   12/11/2016     JAMES     ERIC    ASSAULT      ASL1316  ASL1316F6     10KW   \n",
       "\n",
       "   sentence_type_code  effective_sentence_months  fiscal_year  life_sentence  \n",
       "0                 3.0                       18.0       2018.0            0.0  \n",
       "1                 3.0                       10.0       2019.0            0.0  \n",
       "4                 3.0                        7.0       2017.0            0.0  \n",
       "5                 3.0                        7.0       2019.0            0.0  \n",
       "7                 3.0                       14.0       2017.0            0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_va_sentence_df = pd.read_csv(\n",
    "    '../../state/VA/VA_data/unprocessed_va_historical_sentences_v2.csv',\n",
    "    sep='\\t'\n",
    ")\n",
    "raw_va_sentence_df['crime_type'] = raw_va_sentence_df['Offense Group'].ffill()\n",
    "raw_va_sentence_df['offense_code'] = raw_va_sentence_df['VCC'].ffill()\n",
    "raw_va_sentence_df['crime'] = raw_va_sentence_df['Off1VCC'].ffill()\n",
    "raw_va_sentence_df['judge_id'] = raw_va_sentence_df['JudgeID'].ffill()\n",
    "raw_va_sentence_df['sentence_type_code'] = raw_va_sentence_df['ActDisp'].ffill()\n",
    "raw_va_sentence_df['effective_sentence_months'] = raw_va_sentence_df['effsent']\n",
    "raw_va_sentence_df['fiscal_year'] = raw_va_sentence_df['FiscalYr'].ffill()\n",
    "raw_va_sentence_df['life_sentence'] = raw_va_sentence_df['EffLif']\n",
    "raw_va_sentence_df = raw_va_sentence_df.rename({'Off1Date':'offense_date'}, axis=1)\n",
    "raw_va_sentence_df = raw_va_sentence_df[raw_va_sentence_df.sentence_type_code != 1]\n",
    "raw_va_sentence_df = raw_va_sentence_df[raw_va_sentence_df.effective_sentence_months != 0]\n",
    "\n",
    "raw_va_sentence_df = raw_va_sentence_df[~raw_va_sentence_df['crime_type'].str.contains('Total')]\n",
    "raw_va_sentence_df = raw_va_sentence_df.drop(\n",
    "    ['VCC', 'Offense Group', 'Off1VCC', 'JudgeID', 'ActDisp', 'effsent', 'FiscalYr', 'EffLif'],\n",
    "    axis=1\n",
    ")\n",
    "raw_va_sentence_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22536ebc",
   "metadata": {},
   "source": [
    "We can see the first few rows of the dataset above, but let's take a slightly more comprehensive peak at what's in here before we move on! You can run the following cells without changing anything, but feel free to play with them anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always a good place to start!\n",
    "raw_va_sentence_df.describe([0.05,0.25,0.5,0.75,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aae00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine first and last name into one full name and check the number of rows of data per person\n",
    "raw_va_sentence_df['full_name'] = raw_va_sentence_df.OffFName + ' ' + raw_va_sentence_df.OffLName\n",
    "sentences_per_person = raw_va_sentence_df.groupby('full_name').count().sort_values('OffLName', ascending=False)\n",
    "plt.hist(sentences_per_person.OffLName, bins = 30)\n",
    "plt.ylabel('number of people')\n",
    "plt.xlabel('number of rows of data per person')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fce95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap sentence lengths at 25 years, then plot the sentence length distribution in months.\n",
    "temp = raw_va_sentence_df.copy()\n",
    "temp.loc[temp.effective_sentence_months > 12 * 25, 'effective_sentence_months'] = 12 * 25\n",
    "plt.hist(temp.effective_sentence_months, bins=40)\n",
    "plt.ylabel('number of people')\n",
    "plt.xlabel('length of sentence in months')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef54a5",
   "metadata": {},
   "source": [
    "## outflows_data\n",
    "Ok, time to process our data! First up is the outflows_data table. As a reminder, outflows_data counts the number of people transitioning historically into and throughout the system. We're keeping it simple for now, so we'll just use one historical average admission number. Here is what a final outflows_data table should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'compartment': ['pretrial', 'pretrial'],\n",
    "    'outflow_to': ['prison'] * 2, # this is the same as writing it out two times\n",
    "    'crime_type': ['NA'] * 2,\n",
    "    'time_step': [0,1],\n",
    "    'total_population': [250, 233]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b88e31",
   "metadata": {},
   "source": [
    "Okee you're up! Turn `raw_va_sentence_df` into an outflows_data table! Some important tips for this:\n",
    "* Make sure your table has exactly the right columns with the right names when you're done. df.rename() is your friend!\n",
    "* `time_step` is the number of steps away from the reference date you're at. So with a reference date of 2020.0 and a time_step of 1 year, 2021.0 would be time_step = 1. In our case, the reference_date is 2019.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaec467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Use sub_df = df[*logical condition on column*] to get the subset of data for just 2019. \n",
    "#* your code here *\n",
    "\n",
    "# Step 2: Use len(df) to calculate the number of people sentenced to prison time in 2019. \n",
    "#* your code here *\n",
    "\n",
    "# Step 3: Create a one row dataframe with the datapoint we just derived that matches the columns of the example  \n",
    "# in the cell above.\n",
    "#* your code here *\n",
    "\n",
    "# Step 4: Ensure the columns of our table have the correct types. In particular, make sure the `time_step` column\n",
    "# has type int and `total_population` column has type float. You can use df.col_name = df.col_name.astype(type)\n",
    "#* your code here *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4562a9",
   "metadata": {},
   "source": [
    "Whoooo look at you go!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d14f5f",
   "metadata": {},
   "source": [
    "## transitions_data\n",
    "On to the transitions_data table. Transitions_data should have one row of data per full compartment (aka every one except pretrial) that captures the average length of stay (LOS) in that compartment. Here is what a final transitions table should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'compartment': ['prison'] * 2 + ['release'] * 1,\n",
    "    'outflow_to': ['release'] * 3,\n",
    "    'crime_type': ['NA'] * 3,\n",
    "    'compartment_duration': [48,156, 1],\n",
    "    'total_population': [0.6, 0.4, 1]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186eca0",
   "metadata": {},
   "source": [
    "Okee you're up! Turn `raw_va_sentence_df` into a transitions_data table! Some important tips for this:\n",
    "* Make sure you make a copy of `raw_va_sentence_df` and mess with that. If you start changing the original you won't have anything to build the other data inputs with.\n",
    "* Make sure your table has exactly the right columns with the right names when you're done. df.rename() is your friend!\n",
    "* Our time steps are one year, make sure the units of your `compartment_duration` column are correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Use df.col_name.mean() on the appropriate column to get the average LOS across all sentences.\n",
    "\n",
    "#* your code here *\n",
    "\n",
    "# Step 2: Convert units using avg_LOS = avg_LOS * scale_factor\n",
    "\n",
    "#* your code here *\n",
    "\n",
    "# Step 3: You've now finished the transitions data for the prison compartment, but we still need transitions data\n",
    "# for the release compartment. For our purposes, we're gonna assume no recidivism, which means people can just go\n",
    "# from release back to release (just like the example in the cell above).\n",
    "# Create a dataframe with two rows, one for the prison LOS and one for release back to itself, that matches \n",
    "# the columns of the example in the cell above. Since there's only one row per compartment, you can just\n",
    "# set the total_population column to 1 for both.\n",
    "\n",
    "#* your code here *\n",
    "\n",
    "# Step 4: Ensure the columns of our table have the correct types. In particular, make sure the `compartment_duration`\n",
    "# and `total_population` columns both have type float.\n",
    "\n",
    "#* your code here *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6badaf",
   "metadata": {},
   "source": [
    "Killin it!! Now let's take a look at what we just made and sanity-check that it looks reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbcbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5135f8",
   "metadata": {},
   "source": [
    "## total_population_data\n",
    "Last but not least: the total_population table. You'll have to go grab data for this one yourself, the data you need is on page 37 of this [report](https://vadoc.virginia.gov/media/1623/vadoc-financial-annual-mis-report-2020.pdf).\n",
    "\n",
    "We just need the total population for the year 2019, with which we'll make our final data input table. total_population_data should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'compartment': ['prison'] * 4,\n",
    "    'time_step': range(3,7),\n",
    "    'total_population': [2500, 2800, 3030, 2820]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2c6dc",
   "metadata": {},
   "source": [
    "Okee you're up! Turn the table from the DOC report into a `total_population_data` table! Some important tips for this:\n",
    "* Make sure your table has exactly the right columns with the right names when you're done.\n",
    "* `time_step` is the number of steps away from the reference date you're at. So with a reference date of 2020.0 and a time_step of 1 year, 2022.0 would be time_step = 2. In our case, the reference_date is 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecca530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Input the data from the DOC report into a pandas DataFrame. Feel free to start with the example table\n",
    "# above if that's easier. \n",
    "\n",
    "#* your code here *\n",
    "\n",
    "# Step 2: Ensure the columns of our table have the correct types. In particular, make sure the `time_step` column has\n",
    "# type int and `total_population` column has type float. You can use df.col_name = df.col_name.astype(type)\n",
    "\n",
    "#* your code here *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a3ec0d",
   "metadata": {},
   "source": [
    "## Uploading our data\n",
    "The final step in pre-processing is to upload our data to Google BigQuery. If this next cell gives you a permission error, you need to go set up your Google Cloud access–follow these steps:\n",
    "1. Work through just the installation section of [this page](https://cloud.google.com/sdk/docs/quickstart). Make sure you log in with your Stanford email.\n",
    "2. Open a terminal window and navigate to your Github repository folder. Run the following commands:\n",
    "3. `gcloud auth application-default login` --> This will prompt you to log in to your google cloud account\n",
    "4. `gcloud config set project recidiviz-staging`\n",
    "\n",
    "Once you're set up, you can try the upload again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd921c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: pick a `simulation_tag` for your simulation. \"paco_parole_test\" would be a reasonable example...\n",
    "simulation_tag = \"\"\n",
    "\n",
    "\n",
    "upload_spark_model_inputs(\n",
    "    \"recidiviz-staging\",\n",
    "    simulation_tag,\n",
    "    outflows_data,\n",
    "    transitions_data,\n",
    "    total_population_data,\n",
    "    '../../state/VA/2022/test_configurations/walkthru_user_inputs.yaml',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5d0d2",
   "metadata": {},
   "source": [
    "# Running a baseline\n",
    "We're ready to build a simulation now! First step is initializing a simulation object, called a SuperSimulation. When we initialize it we pass in the filepath of our YAML configuration, so before you continue you need to go to that file, located in `recidiviz-data/recidiviz/calculator/modeling/population_projection/state/VA/2022/test_configurations`, and change the simulation_tag to match the one you chose above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about any warnings. As long as this doesn't fail, you're in business\n",
    "spark_sim = SuperSimulationFactory.build_super_simulation(\n",
    "    '../../state/VA/2022/test_configurations/walkthru_user_inputs.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c19517e",
   "metadata": {},
   "source": [
    "Now we're going to run a baseline simulation. This is an oppportunity to make sure the data we generated is valid, and to sanity-check the basic dynamics it generates. You should just be able to run the code below, but if you feel like it you can also include `release` in the `display_compartments` list to see that population evolve too.\n",
    "*Make sure you pause to think about the graph this generates*. Do you believe this is actually close to reality? Is there something off, and if so what might be causing it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This can take several minutes to run. You'll see six checkpoints printed out along the way before it finishes.\n",
    "display_compartments = ['prison']\n",
    "spark_sim.simulate_baseline(display_compartments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bbfca6",
   "metadata": {},
   "source": [
    "# Running a policy scenario\n",
    "I've filled out a lot of the code for you here, but once you finish out the missing pieces, definitely play around with the stuff I did for you. The whole appeal of the Spark model is how easy it is to test out different policy scenarios once you get the baseline running.\n",
    "\n",
    "Without worrying about all the details, the main thing to understand here is that a policy function transforms the transitions data of a given compartment. By applying one or multiple per compartment that is affected in the policy scenario, we can simulate the effects of the reform in question. `policy_list` is thus just a list of policy functions that gets passed into the simulation so it knows what to change in the policy scenario.\n",
    "\n",
    "Some important pointers:\n",
    "* A SparkPolicy specifies both compartment and subgroup. If you want a policy to apply to every subgroup you need one SparkPolicy per subgroup!\n",
    "* Retroactivity determines whether or not a policy applies to people who are already incarcerated. Try toggling it on and off and see what happens!\n",
    "* Order matters! If policy A shortens sentences by 50% and policy B shortens them by 1 year, the policy_list [A,B] will be different from the policy_list [B,A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e73ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start, let's model enabling parole by shortening the fraction of their sentence that people must serve.\n",
    "# Currently, they cannot serve less than 85%. Let's suppose that this policy will bring that number down to 60%,\n",
    "# and do so for everyone in prison. Think about how you should shorten prison transitions to capture that change, \n",
    "# then pick the appropriate parameters below!\n",
    "\n",
    "REDUCTION_TYPE = ?? # This should either be '*' or '+'. If you make it '+', it will change compartment_duration L to\n",
    "                    # L - LOS_REDUCTION. If you make it '*', it will change L to L * (1 - LOS_REDUCTION)\n",
    "LOS_REDUCTION = ?? # This parameter determines how much shorter compartment duration gets for affected individuals.\n",
    "AFFECTED_FRACTION = ?? # This parameter determines the fraction of the compartment population affected by the change.\n",
    "RETROACTIVE = ?? # This should either be True or False\n",
    "\n",
    "#### Should not have to change things below this line for this cell ####\n",
    "\n",
    "def apply_reinstated_parole():\n",
    "    return partial(TransitionTable.apply_reduction, \n",
    "                   reduction_df=pd.DataFrame({\n",
    "                       'outflow': [OUTFLOW],\n",
    "                       'reduction_size': [LOS_REDUCTION], \n",
    "                       'affected_fraction': [AFFECTED_FRACTION]\n",
    "                   }),\n",
    "                   reduction_type=REDUCTION_TYPE,\n",
    "                   retroactive=RETROACTIVE)\n",
    "\n",
    "# Note that I've created for you in this example, you don't have to build it yourself just yet.\n",
    "policy_list = [SparkPolicy(policy_fn=apply_reinstated_parole(),\n",
    "                                           spark_compartment='prison',\n",
    "                                           sub_population={'crime_type': 'NA'},\n",
    "                                           policy_ts=24,\n",
    "                                           apply_retroactive=RETROACTIVE)]\n",
    "    \n",
    "test_results = spark_sim.simulate_policy(policy_list, 'prison')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a907e",
   "metadata": {},
   "source": [
    "How do those results look? Does this match your expectation for the magnitude of this policy's impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d44516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try mixing it up a bit. Now I want you to try changing the policy so it only applies to \n",
    "# non-violent offenders. Suppose 60% of people in prison are non-violent.\n",
    "\n",
    "LOS_REDUCTION = ??\n",
    "AFFECTED_FRACTION = ??\n",
    "REDUCTION_TYPE = ??\n",
    "RETROACTIVE = ??\n",
    "# If you're unsure what a variable will do, try running it with different values and see how the results change\n",
    "\n",
    "def apply_reinstated_parole():\n",
    "    return partial(TransitionTable.apply_reduction, \n",
    "                   reduction_df=pd.DataFrame({\n",
    "                       'outflow': [OUTFLOW],\n",
    "                       'reduction_size': [LOS_REDUCTION], \n",
    "                       'affected_fraction': [AFFECTED_FRACTION]\n",
    "                   }),\n",
    "                   reduction_type=REDUCTION_TYPE,\n",
    "                   retroactive=RETROACTIVE)\n",
    "\n",
    "policy_list = [SparkPolicy(policy_fn=apply_reinstated_parole(),\n",
    "                                           spark_compartment='prison',\n",
    "                                           sub_population={'crime_type': 'NA'},\n",
    "                                           policy_ts=24,\n",
    "                                           apply_retroactive=RETROACTIVE)]\n",
    "    \n",
    "test_results = spark_sim.simulate_policy(policy_list, 'prison')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f3abd",
   "metadata": {},
   "source": [
    "How do these results compare to your previous scenario? Is it more or less? By how much? Can you think of a way to validate that that result is reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c152a",
   "metadata": {},
   "source": [
    "# Extensions\n",
    "Try these to get a feel for how each of the things you worked on affects the final result:\n",
    "\n",
    "### Outflows data\n",
    "What happens to the simulation when you change the magnitude of outflows data? What about if you added another year (or years) of data?\n",
    "\n",
    "### Transitions data\n",
    "What happens to the simulation if you change the `compartment_duration` of the transitions data? What about if you add another row of data (e.g. everything else the same but change the `compartment_duration` for the second one)? What happens if you make release feed to prison instead of itself? Why?\n",
    "\n",
    "### Total population data\n",
    "What happens to the simulation if you change the magnitude of the population data? Does it change the beginning and the end of the simulation differently? What happens if you pass an empty table (i.e. `total_population_data = pd.DataFrame()`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a775af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
